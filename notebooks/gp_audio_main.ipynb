{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose of this notebook: Basics of running GP attack\n",
    "# Outputs: Lists of candidate perturbations\n",
    "# Next Steps: Take these outputs and evaluate them to find the best perturbations, measure performance, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements and initial defines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't stress about the future...\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Audio inputs\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "# ML Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup to import custom modules\n",
    "if not f'{os.getcwd()}/../scripts' in sys.path:\n",
    "    sys.path.append(f'{os.getcwd()}/../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text transcripts from audio files\n",
    "import transcription\n",
    "#_ = imp.reload(transcription)\n",
    "\n",
    "# Load audio datasets and get info based upon filenames\n",
    "import audiodatasets\n",
    "#_ = imp.reload(audiodatasets)\n",
    "\n",
    "# Ease of use with my dictionaries\n",
    "import dictmgmt\n",
    "#_ = imp.reload(dictmgmt)\n",
    "\n",
    "# Other miscellaneous utilities (like the timer)\n",
    "import misc\n",
    "#_ = imp.reload(misc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classifier utilities\n",
    "import classifiers\n",
    "#_ = imp.reload(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gp\n",
    "#_ = imp.reload(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some basic variables for this runtime\n",
    "jar = f'{os.getcwd()}/../pickles'\n",
    "model_dir = f'{os.getcwd()}/../models'\n",
    "data_dir = f'{os.getcwd()}/../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets; \"pure\" is digital data, \"RECORDED\" was played and recorded in our target environment E \n",
    "ravdess_files = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_ravdess'))\n",
    "ravdess_files_acoustic = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_ravdess_acoustic'))\n",
    "ravdess_speaker_ids = {audiodatasets.get_speaker_id(key) for key in ravdess_files.keys()}\n",
    "ravdess_sentence_ids = {audiodatasets.get_sentence_id(key) for key in ravdess_files.keys()}\n",
    "\n",
    "tess_files = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess'))\n",
    "tess_files_acoustic = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_avery_1ft'))\n",
    "tess_files_acoustic2 = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_avery_3ft'))\n",
    "tess_files_acoustic3 = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_avery_5ft'))\n",
    "#tess_files_acoustic = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_acoustic_1ft'))\n",
    "#tess_files_acoustic2 = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_acoustic_2ft_usbmic50_btspkr84'))\n",
    "#tess_files_acoustic3 = audiodatasets.list_audio_files(os.path.join(data_dir, 'fixed_tess_acoustic_3ft_usbmic50_btspkr100'))\n",
    "tess_files_acoustic = {**tess_files_acoustic}\n",
    "#tess_files_acoustic = {**tess_files_acoustic, **tess_files_acoustic2, **tess_files_acoustic3}\n",
    "\n",
    "tess_speaker_ids = {audiodatasets.get_speaker_id(key) for key in tess_files.keys()}\n",
    "tess_sentence_ids = {audiodatasets.get_sentence_id(key) for key in tess_files.keys()}\n",
    "all_data_files = {\"PURE\": {**ravdess_files, **tess_files}, \"RECORDED\": {**ravdess_files_acoustic, **tess_files_acoustic}} \n",
    "\n",
    "# save the data file structure\n",
    "pickle.dump(all_data_files, open(os.path.join(jar, 'all_data_files.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these files through our classifier(s) to see what we can correctly classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "emo_classifiers = {\"PURE\": classifiers.models[\"SIMPLE_PURE\"], \"RECORDED\": classifiers.models[\"SIMPLE_RECORDED\"]}\n",
    "feature_extractors = {\"PURE\": classifiers.feature_extractors[\"SIMPLE_PURE\"], \"RECORDED\": classifiers.feature_extractors[\"SIMPLE_RECORDED\"]}\n",
    "label_getters = {\"PURE\": classifiers.label_getters[\"SIMPLE_PURE\"], \"RECORDED\": classifiers.label_getters[\"SIMPLE_RECORDED\"]}\n",
    "\n",
    "valid_classification = {}\n",
    "original_softmax_values = {}\n",
    "\n",
    "if os.path.exists(os.path.join(jar, 'valid_classification.pickle')) and os.path.exists(os.path.join(jar, 'original_softmax_values.pickle')):\n",
    "    valid_classification = pickle.load(open(os.path.join(jar, 'valid_classification.pickle'), 'rb'))\n",
    "    original_softmax_values = pickle.load(open(os.path.join(jar, 'original_softmax_values.pickle'), 'rb'))\n",
    "else:\n",
    "    for key in all_data_files.keys():\n",
    "        dataset = all_data_files[key]\n",
    "        emo_model = emo_classifiers[key]\n",
    "        feature_extractor = feature_extractors[key]\n",
    "        label_getter = label_getters[key]\n",
    "\n",
    "        X_vals, y_vals, featureindices = feature_extractor(dataset)\n",
    "        predictions = emo_model.predict(X_vals) \n",
    "\n",
    "        for sample_key in featureindices.keys():\n",
    "            actual, predicted = label_getter(y_vals, predictions, featureindices[sample_key])\n",
    "            dictmgmt.dictset(original_softmax_values, [key, sample_key], copy.deepcopy(predictions[featureindices[sample_key]]))\n",
    "\n",
    "            if actual == predicted:\n",
    "                dictmgmt.dictset(valid_classification, [key, sample_key], all_data_files[key][sample_key])\n",
    "    pickle.dump(valid_classification, open(os.path.join(jar, 'valid_classification.pickle'), 'wb'))\n",
    "    pickle.dump(original_softmax_values, open(os.path.join(jar, 'original_softmax_values.pickle'), 'wb'))\n",
    "\n",
    "misc.elapsedTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these files through our transcription service to see what we can correctly transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "all_transcripts = {}\n",
    "all_confidences = {}\n",
    "\n",
    "if os.path.exists(os.path.join(jar, 'all_transcripts.pickle')) and os.path.exists(os.path.join(jar, 'all_confidences.pickle')):\n",
    "    all_transcripts = pickle.load(open(os.path.join(jar, 'all_transcripts.pickle'), 'rb'))\n",
    "    all_confidences = pickle.load(open(os.path.join(jar, 'all_confidences.pickle'), 'rb'))\n",
    "else:\n",
    "    for key in all_data_files.keys():\n",
    "        transcripts, confidences = transcription.extract_text(all_data_files[key])\n",
    "        all_transcripts[key] = transcripts\n",
    "        all_confidences[key] = confidences\n",
    "\n",
    "    pickle.dump(all_transcripts, open(os.path.join(jar, 'all_transcripts.pickle'), 'wb'))\n",
    "    pickle.dump(all_confidences, open(os.path.join(jar, 'all_confidences.pickle'), 'wb'))\n",
    "    \n",
    "misc.elapsedTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "# Next, validate the transcripts and drop everything else\n",
    "valid_transcripts = {}\n",
    "valid_confidences = {}\n",
    "\n",
    "if os.path.exists(os.path.join(jar, 'valid_transcripts.pickle')) and os.path.exists(os.path.join(jar, 'valid_confidences.pickle')):\n",
    "    valid_transcripts = pickle.load(open(os.path.join(jar, 'valid_transcripts.pickle'), 'rb'))\n",
    "    valid_confidences = pickle.load(open(os.path.join(jar, 'valid_confidences.pickle'), 'rb'))\n",
    "else:\n",
    "    for key in all_data_files.keys():\n",
    "        _, transcripts, confidences = transcription.remove_transcription_errors(all_data_files[key], all_transcripts[key], all_confidences[key])\n",
    "        valid_transcripts[key] = transcripts\n",
    "        valid_confidences[key] = confidences\n",
    "\n",
    "    pickle.dump(valid_transcripts, open(os.path.join(jar, 'valid_transcripts.pickle'), 'wb'))\n",
    "    pickle.dump(valid_confidences, open(os.path.join(jar, 'valid_confidences.pickle'), 'wb'))\n",
    "    \n",
    "misc.elapsedTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(valid_classification, open(os.path.join(jar, 'valid_classification.pickle'), 'wb'))\n",
    "pickle.dump(original_softmax_values, open(os.path.join(jar, 'original_softmax_values.pickle'), 'wb'))\n",
    "pickle.dump(all_transcripts, open(os.path.join(jar, 'all_transcripts.pickle'), 'wb'))\n",
    "pickle.dump(all_confidences, open(os.path.join(jar, 'all_confidences.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.alert_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Now, we just need to take the intersection of the validly classified and validly transcribed; this is our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evasive_todo = {}\n",
    "\n",
    "for key in all_data_files.keys():\n",
    "    for sample_key in all_data_files[key].keys():\n",
    "        if sample_key in valid_transcripts[key] and sample_key in valid_classification[key].keys():\n",
    "            dictmgmt.dictset(evasive_todo, [key, sample_key], all_data_files[key][sample_key])\n",
    "\n",
    "    a = len(all_data_files[key])\n",
    "    b = len(valid_classification[key])\n",
    "    c = len(valid_transcripts[key])\n",
    "    d = len(evasive_todo[key])\n",
    "    print(f\"Original {key} Dataset: {a} | Correctly Classified: {b} | Correctly Transcribed: {c} | Intersection: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, load any autoencoders for use estimating the target environment E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, sample_weight=None, **kwargs):\n",
    "    foo = tf.real(tf.signal.fft(tf.complex(y_true, 0.0)))\n",
    "    foo1 = tf.real(tf.signal.fft(tf.complex(y_pred, 0.0)))\n",
    "    return keras.losses.mean_squared_error(foo, foo1)\n",
    "\n",
    "# Update: Removed autoencoders because they did not significantly improve performance\n",
    "\n",
    "#autoencoders = { \"MSE\": keras.models.load_model(f'{model_dir}/autoencoder.h5'),\n",
    "#                 \"MSE-FFT\": keras.models.load_model(f'{model_dir}/autoencoder_customloss.h5', custom_objects={\"custom_loss\":custom_loss})\n",
    "#               }\n",
    "#autoencoders = { \"MSE\": keras.models.load_model(f'{model_dir}/autoencoder.h5'),\n",
    "#                 \"MSE-FFT\": keras.models.load_model(f'../data/autoencoder_custom_avery.h5', custom_objects={\"custom_loss\":custom_loss})\n",
    "#               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we've got the dataset and the parts for our validation framework, setup the GP environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some baseline perturbation characteristics; in general, should not change these between runs\n",
    "min_freq=100\n",
    "max_freq=4000 \n",
    "min_duration=2.5\n",
    "max_duration=4.0\n",
    "min_offset=0.0 \n",
    "max_offset=0.5\n",
    "min_muzzle=25\n",
    "max_muzzle=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I need to define my fitness function; this leverages a lot of global variables b/c of how DEAP is written\n",
    "# (Technically, DEAP supports more than one, but this is simpler and works more consistently)\n",
    "# At a high level:\n",
    "# def evaluate():\n",
    "#     Sample the training dataset\n",
    "#     Turn the individual candidate into a perturbation\n",
    "#     Apply the perturbation to the sample\n",
    "#     score = text_transcription_goodness * classification_fool_score\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a single perturbation to a single file\n",
    "def apply_perturbation(individual, audio_key, filelist, temp_dir='/tmp/bpt', max_duration=4.0, sample_rate=48000, autoencoder_key=None):\n",
    "\n",
    "    # Everything is file based...make sure that the temp directory is there\n",
    "    Path(temp_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    x, sr = librosa.load(filelist[audio_key], duration=max_duration, sr=sample_rate)\n",
    "\n",
    "    new_x = x\n",
    "    for freq,duration,offset,muzzle in zip(individual[::4], individual[1::4], individual[2::4], individual[3::4]):\n",
    "\n",
    "        # Adjust normalized values\n",
    "        freq = freq * (max_freq - min_freq) + min_freq\n",
    "        duration = duration * (max_duration - min_duration) + min_duration\n",
    "        offset = offset * (max_offset - min_offset) + min_offset\n",
    "        muzzle = muzzle * (max_muzzle - min_muzzle) + min_muzzle\n",
    "        \n",
    "        tone = librosa.tone(freq, duration=duration, sr=sample_rate)\n",
    "        tone = tone/muzzle\n",
    "        int_off = int(sr * offset)\n",
    "        \n",
    "        # Called if we are running acoustically (i.e. - using the autoencoder to simulate the room's acoustics)\n",
    "#        if not autoencoder_key is None:\n",
    "#            tone = librosa.util.fix_length(tone, int(max_duration*sample_rate))\n",
    "            \n",
    "            # Need to resample down and up for the autoencoder (ae hardcoded to sr=10000)\n",
    "#            tone = librosa.resample(tone, orig_sr=sample_rate, target_sr=10000)\n",
    "#            acoustic_tone = autoencoders[autoencoder_key].predict(np.array([np.reshape(tone, (np.shape(tone)[0], 1))]))[0]\n",
    "#            acoustic_tone = librosa.resample(tone, orig_sr=10000, target_sr=sample_rate)\n",
    "#            tone=acoustic_tone\n",
    "        \n",
    "        for indx in range(int_off, min(len(tone)+int_off, len(new_x))):\n",
    "            new_x[indx] += tone[indx-int_off]\n",
    "\n",
    "    sf.write(f'{temp_dir}/{audio_key}', new_x, sample_rate, )\n",
    "    return(f'{temp_dir}/{audio_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One important attribute is the impact of tones on the extracted text; returns a value in [0, 1]\n",
    "# This goes to 0 if there are ANY new transcription errors\n",
    "# The score is decreased linearly with any impacts to confidence\n",
    "def measure_text_extract_goodness(new_transcripts, new_confidences, orig_confidences):\n",
    "    retval = 1.0\n",
    "    num_samples = len(new_transcripts)\n",
    "    \n",
    "    for key, text in new_transcripts.items():\n",
    "        if not transcription.valid_transcript(text):\n",
    "            retval = 0.0\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            if new_confidences[key] < orig_confidences[key]:\n",
    "                retval -= (orig_confidences[key] - new_confidences[key]) / num_samples\n",
    "        except KeyError:\n",
    "            # Skip this one if there is a KeyError (shouldn't happen)\n",
    "            print(f'Key Error: {key}')\n",
    "            \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another important factor is the classifier score; if this modification pushes me towards a different class, then we get credit for that\n",
    "# Modified files is a dictionary with key=filename (same is the original) and value=path to possibly evasive file\n",
    "# Impacts to score will be compared with values in the  original_softmax_results dictionary generated earlier\n",
    "\n",
    "def measure_classification_degradation( \n",
    "                                        classifier, # classifier being used\n",
    "                                        feature_extractor, # feature extractor for this classifier\n",
    "                                        label_getter, # knows how to parse the results\n",
    "                                        original_softmax, # dict containing softmax values for original files\n",
    "                                        modified_files, # dict containing files that we have modified to fool the classifier \n",
    "                                        misclassification_bonus=50, # Bonus given to score if we have an actual misclassification \n",
    "                                        target_class=None\n",
    "                                      ):\n",
    "\n",
    "    score = 0.0\n",
    "    \n",
    "    X_vals, y_vals, featureindices = feature_extractor(modified_files)\n",
    "    predictions = classifier.predict(X_vals) \n",
    "\n",
    "    for sample_key in featureindices.keys():\n",
    "        actual, predicted = label_getter(y_vals, predictions, featureindices[sample_key])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Bonus for misclassifications\n",
    "        if target_class is None: # untargeted evason\n",
    "\n",
    "            score += max(original_softmax[sample_key][actual]-predictions[featureindices[sample_key]][actual], 0)\n",
    "            \n",
    "            # Bonus\n",
    "            if actual != predicted:\n",
    "                score += misclassification_bonus\n",
    "        else: # targeted evason\n",
    "\n",
    "            score += max(predictions[featureindices[sample_key]][target_class] - original_softmax[sample_key][target_class], 0)\n",
    "\n",
    "            # Bonus\n",
    "            if predicted == target_class:\n",
    "                score += misclassification_bonus\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we pull together all of these measures into a single fitness measure\n",
    "# DEAP does support multiple, independent fitness measures but they were not working for me\n",
    "def evaluation(individual):\n",
    "    \n",
    "    # The globals used by this function are stored in a dictionary\n",
    "    global evaluation_dictionary\n",
    "    \n",
    "    evaluation_file_list = evaluation_dictionary[\"Evaluation File List\"]\n",
    "    evaluation_sample_size = evaluation_dictionary[\"Evaluation Sample Size\"]\n",
    "    original_transcription_confidences = evaluation_dictionary[\"Original Transcription Confidences\"]\n",
    "    evaluation_autoencoder_key = evaluation_dictionary[\"Evaluation Autoencoder Key\"]\n",
    "    evaluation_classifier_modality = evaluation_dictionary[\"Evaluation Classifier Modality\"] # PURE|RECORDED\n",
    "    target_class = evaluation_dictionary[\"Target Class\"]\n",
    "    original_softmax = evaluation_dictionary[\"Original Softmax Values\"]\n",
    "    \n",
    "    # Derive a few from the classifier modality\n",
    "    emo_classifier = emo_classifiers[evaluation_classifier_modality]\n",
    "    feature_extractor = feature_extractors[evaluation_classifier_modality]\n",
    "    label_getter = label_getters[evaluation_classifier_modality]\n",
    "\n",
    "    # Take a random sample and generate modified versions of these files using individual's perturbation\n",
    "    sample_keys = random.sample(list(evaluation_file_list), min(evaluation_sample_size, len(evaluation_file_list)))\n",
    "\n",
    "    modified_files = { key:apply_perturbation(individual=individual, audio_key=key, filelist=evaluation_file_list, autoencoder_key=evaluation_autoencoder_key) \\\n",
    "                      for key in sample_keys \n",
    "                     }\n",
    "\n",
    "    # Now, assess the fitness of this individual\n",
    "    fitness_score = 0.0\n",
    "\n",
    "    if len(modified_files) > 0:\n",
    "        classifier_fool_score = measure_classification_degradation( classifier=emo_classifier, \n",
    "                                                                    feature_extractor=feature_extractor,\n",
    "                                                                    label_getter=label_getter,\n",
    "                                                                    original_softmax=original_softmax,\n",
    "                                                                    modified_files=modified_files,\n",
    "                                                                    target_class=target_class\n",
    "                                                                  )\n",
    "        text_extract_score = 0.0\n",
    "\n",
    "        # Only waste time on the text extraction if we are making some progress with the classifier\n",
    "        if classifier_fool_score > 0.0:\n",
    "\n",
    "            # Adding some retires in here becaue the VOSK stuff is a little buggy (with the model that I'm using)\n",
    "            eval_transcripts = {}\n",
    "            eval_confidences = {}\n",
    "\n",
    "            # 10 retries should be enough\n",
    "            for _ in range(10):\n",
    "                if len(modified_files) == 0:\n",
    "                    break\n",
    "\n",
    "                new_transcripts, new_confidences = transcription.extract_text(modified_files)\n",
    "\n",
    "                remove_me = []\n",
    "                for key in new_transcripts.keys():\n",
    "                    if new_confidences[key] != 0.0:\n",
    "                        eval_transcripts[key] = new_transcripts[key]\n",
    "                        eval_confidences[key] = new_confidences[key]\n",
    "                        remove_me.append(key)\n",
    "\n",
    "                for key in remove_me:\n",
    "                    del modified_files[key]\n",
    "\n",
    "            text_extract_score = measure_text_extract_goodness(new_transcripts, new_confidences, original_transcription_confidences)\n",
    "\n",
    "        fitness_score = text_extract_score*classifier_fool_score\n",
    "\n",
    "    return fitness_score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we initialize the GP environment and then we are ready to start evaluations\n",
    "gp.initialize_gp_environment(fitness_function=evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.alert_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 0: \n",
    "#    - Part of rewrite; let's just build a few EONs (new AAP name) based upon different group deographics\n",
    "\n",
    "# Generate based upon gender; RAVDESS ONLY\n",
    "misc.resetTimer()\n",
    "\n",
    "groups = {\"male\": [1, 3, 5, 7, 9], \"female\": [0, 2, 4, 6, 8], \"2male3female\": [11, 13, 14, 16, 18], \"3male2female\": [11, 13, 15, 16, 18]}\n",
    "\n",
    "for gender in groups:\n",
    "    if gender == \"male\" or gender == \"female\":\n",
    "        continue\n",
    "    \n",
    "    evaluation_dictionary = {}\n",
    "    evaluation_dictionary[\"Evaluation File List\"] = {\n",
    "\n",
    "        sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "            if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids and \\\n",
    "               audiodatasets.get_speaker_id(sample_key) in groups[gender]\n",
    "\n",
    "    }\n",
    "    evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "    evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "    evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "    evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "    evaluation_dictionary[\"Target Class\"] = None\n",
    "    evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "    gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "    populations,_ = gp.run_gp(number_of_generations=40)\n",
    "\n",
    "    pops = []\n",
    "    for x in populations:\n",
    "        pops.append([])\n",
    "        for y in x:\n",
    "            pops[-1].append(list(y))\n",
    "\n",
    "    populations = pops\n",
    "    \n",
    "    pops_fn = f\"populations_RAVDESS40_GENDER_{gender}.pickle\"\n",
    "    pickle.dump(populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "    print(f\"Completed {gender}\")\n",
    "    misc.elapsedTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: \n",
    "#    - Train on RAVDESS data for 40 generations\n",
    "#    - Train on TESS data for an additional 10 generations\n",
    "#    - TESS we do a 30/30/140 split based upon phrases from the dataset\n",
    "#    - Training and Testing use the MSE autoencoder\n",
    "#    - Evaluation will be done elsewhere (will require playing the perturbations in environment E, recording, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "# Part 1: Train on RAVDESS for 40 generations\n",
    "\n",
    "# Setup the evaluation environment\n",
    "evaluation_dictionary = {}\n",
    "evaluation_dictionary[\"Evaluation File List\"] = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                 if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "#evaluation_dictionary[\"Evaluation Sample Size\"] = 20\n",
    "\n",
    "# We are starting with a pretrained model, so we need to go w/o any info about the target environment E\n",
    "evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "evaluation_dictionary[\"Target Class\"] = None\n",
    "evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "# Load the populations from a RAVDESS run; \n",
    "# If I didn't have this pickle, I would run:\n",
    "#   evaluation_dictionary[\"Evaluation File List\"] = { key:evasive_todo[\"RECORDED\"][key] for key in evasive_todo[\"RECORDED\"] \\\n",
    "#                                                     if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "print(\"\\n=======================================================================================\")\n",
    "print(f\"RAVDESS/TESS: RAVDESS Digital run\")\n",
    "print(\"=======================================================================================\\n\")\n",
    "\n",
    "#ravdess_populations, _ = gp.run_gp(starting_population=None, number_of_generations=40)\n",
    "#pickle.dump(ravdess_populations, open(f\"{jar}/populations_START_RAVDESS40_PLUS_TESS_10GEN.pickle\", 'wb'))\n",
    "ravdess_populations = pickle.load(open(f'{jar}/populations_RAVDESS_UNTARGETED_CONTINUED.pickle', 'rb'))\n",
    "\n",
    "print(f\"Completed.\")\n",
    "misc.elapsedTime()\n",
    "\n",
    "# Part 2: Train on a subset of the TESS dataset\n",
    "autoencoder_keys = ['PURE']\n",
    "#autoencoder_keys = ['PURE', 'MSE', 'MSE-FFT']\n",
    "#splits = [80, 80, 80]\n",
    "splits = [100, 100, 100]\n",
    "\n",
    "for run_indx in range(len(autoencoder_keys)):\n",
    "\n",
    "    if autoencoder_keys[run_indx] == 'PURE':\n",
    "        ae_id = None\n",
    "    else:\n",
    "        ae_id = autoencoder_keys[run_indx]\n",
    "    ss = splits[run_indx]//2\n",
    "        \n",
    "    for trial_indx in range(1,3):\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"RAVDESS/TESS: Splits {ss}_{ss}_{200-ss*2}, Autoencoder: {autoencoder_keys[run_indx]}, Trial {trial_indx+1} of 2\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "\n",
    "#        pops_fn = f\"populations_DIGITAL_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "#        samples_fn = f\"samples_DIGITAL_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "        \n",
    "        pops_fn = f\"populations_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_MULTDIST_AVERY_10GEN.pickle\"\n",
    "        samples_fn = f\"samples_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_MULTDIST_AVERY_10GEN.pickle\"\n",
    "        \n",
    "        if not os.path.exists(f\"{jar}/{pops_fn}\"):\n",
    "            sample = random.sample(list(tess_sentence_ids), 60)\n",
    "#            train_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "#                                                             if audiodatasets.get_sentence_id(sample_key) in sample[:ss] } \n",
    "#            test_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "#                                                             if audiodatasets.get_sentence_id(sample_key) in sample[ss:] } \n",
    "#            eval_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "#                                                             if not audiodatasets.get_sentence_id(sample_key) in sample } \n",
    "\n",
    "            train_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[:ss] } \n",
    "            test_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[ss:] } \n",
    "            eval_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if not audiodatasets.get_sentence_id(sample_key) in sample } \n",
    "\n",
    "            pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(f\"{jar}/{samples_fn}\", 'wb'))\n",
    "\n",
    "            evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "            evaluation_dictionary[\"Evaluation Autoencoder Key\"] = ae_id\n",
    "            evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"RECORDED\"]\n",
    "            evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"RECORDED\"\n",
    "            evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"RECORDED\"]\n",
    "\n",
    "            populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "            pops = []\n",
    "            for x in populations:\n",
    "                pops.append([])\n",
    "                for y in x:\n",
    "                    pops[-1].append(list(y))\n",
    "\n",
    "            populations = pops\n",
    "            pickle.dump( populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "\n",
    "        print(f\"Completed trial {trial_indx}\")\n",
    "        misc.elapsedTime()\n",
    "    \n",
    "# Part 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.alert_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalized perturbations\n",
    "len(evaluation_dictionary['Evaluation File List'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "# Part 1: Train on RAVDESS for 40 generations\n",
    "\n",
    "# Setup the evaluation environment\n",
    "evaluation_dictionary = {}\n",
    "evaluation_dictionary[\"Evaluation File List\"] = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                 if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "#evaluation_dictionary[\"Evaluation Sample Size\"] = 20\n",
    "\n",
    "# We are starting with a pretrained model, so we need to go w/o any info about the target environment E\n",
    "evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "evaluation_dictionary[\"Target Class\"] = None\n",
    "evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "# Load the populations from a RAVDESS run; \n",
    "# If I didn't have this pickle, I would run:\n",
    "#   evaluation_dictionary[\"Evaluation File List\"] = { key:evasive_todo[\"RECORDED\"][key] for key in evasive_todo[\"RECORDED\"] \\\n",
    "#                                                     if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "print(\"\\n=======================================================================================\")\n",
    "print(f\"RAVDESS/TESS: RAVDESS Digital run\")\n",
    "print(\"=======================================================================================\\n\")\n",
    "\n",
    "#ravdess_populations, _ = gp.run_gp(starting_population=None, number_of_generations=40)\n",
    "#pickle.dump([x for x in [y for y in ravdess_populations[x]]], open(f\"{jar}/populations_START_RAVDESS40_diff_params_PLUS_TESS_10GEN.pickle\", 'wb'))\n",
    "#ravdess_populations = pickle.load(open(f'{jar}/populations_RAVDESS_UNTARGETED_CONTINUED.pickle', 'rb'))\n",
    "\n",
    "print(f\"Completed.\")\n",
    "misc.elapsedTime()\n",
    "\n",
    "# Do the case with all users to baseline\n",
    "#for trial_indx in range(0,5):\n",
    "#    print(\"\\n=======================================================================================\")\n",
    "#    print(f\"RAVDESS/TESS Personalized: Speaker ID ALL, Trial {trial_indx+1} of 5\")\n",
    "#    print(\"=======================================================================================\\n\")\n",
    "\n",
    "#    pops_fn = f\"populations_PERSONAL_diff_params_{trial_indx:02}_speakerid_ALL_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "#    samples_fn = f\"samples_PERSONAL_diff_params_{trial_indx:02}_speakerid_ALL_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "\n",
    "#    if not os.path.exists(f\"{jar}/{pops_fn}\"):\n",
    "#        total_set = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "#                                                         if audiodatasets.get_speaker_id(sample_key) in tess_speaker_ids }\n",
    "#        total_set = { key:total_set[key] for key in random.sample(list(total_set.keys()), 206) }\n",
    "\n",
    "#        train_keys = random.sample(list(total_set.keys()), int(len(total_set)*.1))\n",
    "#        test_keys = random.sample([k for k in total_set.keys() if k not in train_keys], int(len(total_set)*.1))\n",
    "#        eval_keys = [k for k in total_set.keys() if k not in train_keys and k not in test_keys]\n",
    "\n",
    "#        train_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in train_keys } \n",
    "#        test_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in test_keys } \n",
    "#        eval_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in eval_keys } \n",
    "\n",
    "#        pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(f\"{jar}/{samples_fn}\", 'wb'))\n",
    "\n",
    "#        evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "#        populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "#        pops = []\n",
    "#        for x in populations:\n",
    "#            pops.append([])\n",
    "#            for y in x:\n",
    "#                pops[-1].append(list(y))\n",
    "\n",
    "#        populations = pops\n",
    "#        pickle.dump( populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "\n",
    "#    print(f\"Completed trial {trial_indx}\")\n",
    "#    misc.elapsedTime()\n",
    "\n",
    "\n",
    "\n",
    "for tess_spkr in tess_speaker_ids:\n",
    "    \n",
    "    for trial_indx in range(0,5):\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"RAVDESS/TESS Personalized: Speaker ID {tess_spkr}, Trial {trial_indx+1} of 5\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "\n",
    "        pops_fn = f\"populations_PERSONAL_diff_params_{trial_indx:02}_speakerid_{tess_spkr}_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "        samples_fn = f\"samples_PERSONAL_diff_params_{trial_indx:02}_speakerid_{tess_spkr}_RAVDESS40_PLUS_TESS_10GEN.pickle\"\n",
    "        \n",
    "        if not os.path.exists(f\"{jar}/{pops_fn}\"):\n",
    "            total_set = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                             if audiodatasets.get_speaker_id(sample_key) == tess_spkr } \n",
    "\n",
    "            train_keys = random.sample(list(total_set.keys()), int(len(total_set)*.1))\n",
    "            test_keys = random.sample([k for k in total_set.keys() if k not in train_keys], int(len(total_set)*.1))\n",
    "            eval_keys = [k for k in total_set.keys() if k not in train_keys and k not in test_keys]\n",
    "          \n",
    "            train_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in train_keys } \n",
    "            test_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in test_keys } \n",
    "            eval_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in eval_keys } \n",
    "\n",
    "            pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(f\"{jar}/{samples_fn}\", 'wb'))\n",
    "\n",
    "            evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "            populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "            pops = []\n",
    "            for x in populations:\n",
    "                pops.append([])\n",
    "                for y in x:\n",
    "                    pops[-1].append(list(y))\n",
    "\n",
    "            populations = pops\n",
    "            pickle.dump( populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "\n",
    "        print(f\"Completed trial {trial_indx}\")\n",
    "        misc.elapsedTime()\n",
    "    \n",
    "# Part 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXPLANATION-DRIVEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New experiment - explanation-driven evasion\n",
    "tone_ranges = [[800, 1000], [533, 734], [1071, 1317]]\n",
    "\n",
    "# Applies a single perturbation to a single file\n",
    "def apply_perturbation(individual, audio_key, filelist, temp_dir='/tmp/bpt', max_duration=4.0, sample_rate=48000, autoencoder_key=None):\n",
    "\n",
    "    # Everything is file based...make sure that the temp directory is there\n",
    "    Path(temp_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    x, sr = librosa.load(filelist[audio_key], duration=max_duration, sr=sample_rate)\n",
    "\n",
    "    new_x = x\n",
    "\n",
    "    # NEW FOR EXPLANATION\n",
    "    tone_indx = 0\n",
    "    \n",
    "    for freq,duration,offset,muzzle in zip(individual[::4], individual[1::4], individual[2::4], individual[3::4]):\n",
    "\n",
    "        # Adjust normalized values\n",
    "\n",
    "        # NEW FOR EXPLANATION\n",
    "        freq = freq * (tone_ranges[tone_indx][1] - tone_ranges[tone_indx][0]) + tone_ranges[tone_indx][0]\n",
    "        tone_indx += 1\n",
    "                \n",
    "        duration = duration * (max_duration - min_duration) + min_duration\n",
    "        offset = offset * (max_offset - min_offset) + min_offset\n",
    "        muzzle = muzzle * (max_muzzle - min_muzzle) + min_muzzle\n",
    "        \n",
    "        tone = librosa.tone(freq, duration=duration, sr=sample_rate)\n",
    "        tone = tone/muzzle\n",
    "        int_off = int(sr * offset)\n",
    "        \n",
    "        # Called if we are running acoustically (i.e. - using the autoencoder to simulate the room's acoustics)\n",
    "#        if not autoencoder_key is None:\n",
    "#            tone = librosa.util.fix_length(tone, int(max_duration*sample_rate))\n",
    "            \n",
    "            # Need to resample down and up for the autoencoder (ae hardcoded to sr=10000)\n",
    "#            tone = librosa.resample(tone, orig_sr=sample_rate, target_sr=10000)\n",
    "#            acoustic_tone = autoencoders[autoencoder_key].predict(np.array([np.reshape(tone, (np.shape(tone)[0], 1))]))[0]\n",
    "#            acoustic_tone = librosa.resample(tone, orig_sr=10000, target_sr=sample_rate)\n",
    "#            tone=acoustic_tone\n",
    "        \n",
    "        for indx in range(int_off, min(len(tone)+int_off, len(new_x))):\n",
    "            new_x[indx] += tone[indx-int_off]\n",
    "\n",
    "    sf.write(f'{temp_dir}/{audio_key}', new_x, sample_rate, )\n",
    "    return(f'{temp_dir}/{audio_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.resetTimer()\n",
    "\n",
    "# Part 1: Train on RAVDESS for 40 generations\n",
    "\n",
    "# Setup the evaluation environment\n",
    "evaluation_dictionary = {}\n",
    "evaluation_dictionary[\"Evaluation File List\"] = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                 if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "\n",
    "# We are starting with a pretrained model, so we need to go w/o any info about the target environment E\n",
    "evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "evaluation_dictionary[\"Target Class\"] = None\n",
    "evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "# Load the populations from a RAVDESS run; \n",
    "# If I didn't have this pickle, I would run:\n",
    "#   evaluation_dictionary[\"Evaluation File List\"] = { key:evasive_todo[\"RECORDED\"][key] for key in evasive_todo[\"RECORDED\"] \\\n",
    "#                                                     if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "print(\"\\n=======================================================================================\")\n",
    "print(f\"RAVDESS/TESS: RAVDESS Digital run\")\n",
    "print(\"=======================================================================================\\n\")\n",
    "\n",
    "ravdess_populations, _ = gp.run_gp(starting_population=None, number_of_generations=40)\n",
    "pickle.dump(ravdess_populations, open(f\"{jar}/populations_START_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN.pickle\", 'wb'))\n",
    "#ravdess_populations = pickle.load(open(f'{jar}/populations_START_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN.pickle', 'rb'))\n",
    "\n",
    "print(f\"Completed.\")\n",
    "misc.elapsedTime()\n",
    "\n",
    "# Part 2: Train on a subset of the TESS dataset\n",
    "autoencoder_keys = ['PURE', 'MSE', 'MSE-FFT']\n",
    "splits = [100, 100, 100]\n",
    "\n",
    "for run_indx in range(len(autoencoder_keys)):\n",
    "\n",
    "    if autoencoder_keys[run_indx] == 'PURE':\n",
    "        ae_id = None\n",
    "    else:\n",
    "        ae_id = autoencoder_keys[run_indx]\n",
    "    ss = splits[run_indx]//2\n",
    "        \n",
    "    for trial_indx in range(0,5):\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"RAVDESS/TESS: Splits {ss}_{ss}_{200-ss*2}, Autoencoder: {autoencoder_keys[run_indx]}, Trial {trial_indx+1} of 5\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "\n",
    "        \n",
    "        pops_fn = f\"populations_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN.pickle\"\n",
    "        samples_fn = f\"samples_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN.pickle\"\n",
    "        \n",
    "        if not os.path.exists(f\"{jar}/{pops_fn}\"):\n",
    "            sample = random.sample(list(tess_sentence_ids), 60)\n",
    "\n",
    "            train_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[:ss] and re.match(r'.*[23]ft.*', sample_key) is None} \n",
    "            test_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[ss:] and re.match(r'.*[23]ft.*', sample_key) is None } \n",
    "            eval_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if not audiodatasets.get_sentence_id(sample_key) in sample and re.match(r'.*[23]ft.*', sample_key) is None } \n",
    "\n",
    "            pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(f\"{jar}/{samples_fn}\", 'wb'))\n",
    "\n",
    "            evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "            evaluation_dictionary[\"Evaluation Autoencoder Key\"] = ae_id\n",
    "            evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"RECORDED\"]\n",
    "            evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"RECORDED\"\n",
    "            evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"RECORDED\"]\n",
    "\n",
    "            populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "            pops = []\n",
    "            for x in populations:\n",
    "                pops.append([])\n",
    "                for y in x:\n",
    "                    pops[-1].append(list(y))\n",
    "\n",
    "            populations = pops\n",
    "            pickle.dump( populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "\n",
    "        print(f\"Completed trial {trial_indx}\")\n",
    "        misc.elapsedTime()\n",
    "    \n",
    "# Part 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE TEST...\n",
    "\n",
    "misc.resetTimer()\n",
    "\n",
    "for trial_indx in range(0,5):\n",
    "\n",
    "    starts = [random.randint(0,4000-200), random.randint(0,4000-201), random.randint(0,4000-246)]\n",
    "    tone_ranges = [[starts[0], starts[0]+200], [starts[1], starts[1]+201], [starts[2], starts[2]+246]]\n",
    "\n",
    "    # Part 1: Train on RAVDESS for 40 generations\n",
    "\n",
    "    # Setup the evaluation environment\n",
    "    evaluation_dictionary = {}\n",
    "    evaluation_dictionary[\"Evaluation File List\"] = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                     if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "    evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "\n",
    "    # We are starting with a pretrained model, so we need to go w/o any info about the target environment E\n",
    "    evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "    evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "    evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "    evaluation_dictionary[\"Target Class\"] = None\n",
    "    evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "    gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "    # Load the populations from a RAVDESS run; \n",
    "    # If I didn't have this pickle, I would run:\n",
    "    #   evaluation_dictionary[\"Evaluation File List\"] = { key:evasive_todo[\"RECORDED\"][key] for key in evasive_todo[\"RECORDED\"] \\\n",
    "    #                                                     if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "    print(\"\\n=======================================================================================\")\n",
    "    print(f\"RAVDESS/TESS: RAVDESS Digital run #{trial_indx}\")\n",
    "    print(\"=======================================================================================\\n\")\n",
    "\n",
    "    ravdess_populations, _ = gp.run_gp(starting_population=None, number_of_generations=40)\n",
    "    pickle.dump(ravdess_populations, open(f\"{jar}/populations_START_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN_BASELINE_{trial_indx}.pickle\", 'wb'))\n",
    "    #ravdess_populations = pickle.load(open(f'{jar}/populations_START_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN_BASELINE.pickle', 'rb'))\n",
    "\n",
    "    print(f\"Completed.\")\n",
    "    misc.elapsedTime()\n",
    "\n",
    "    # Part 2: Train on a subset of the TESS dataset\n",
    "    autoencoder_keys = ['PURE', 'MSE', 'MSE-FFT']\n",
    "    splits = [100, 100, 100]\n",
    "\n",
    "    for run_indx in range(len(autoencoder_keys)):\n",
    "\n",
    "        if autoencoder_keys[run_indx] == 'PURE':\n",
    "            ae_id = None\n",
    "        else:\n",
    "            ae_id = autoencoder_keys[run_indx]\n",
    "        ss = splits[run_indx]//2\n",
    "        \n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"RAVDESS/TESS: Splits {ss}_{ss}_{200-ss*2}, Autoencoder: {autoencoder_keys[run_indx]}, Trial {trial_indx+1} of 5\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "        \n",
    "        pops_fn = f\"populations_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN_BASELINE.pickle\"\n",
    "        samples_fn = f\"samples_{trial_indx:02}_ae_{autoencoder_keys[run_indx]}_samples_{ss}_{ss}_{200-ss*2}_RAVDESS40_PLUS_TESS_10GEN_EXPLANATION_DRIVEN_BASELINE.pickle\"\n",
    "        \n",
    "        if not os.path.exists(f\"{jar}/{pops_fn}\"):\n",
    "            sample = random.sample(list(tess_sentence_ids), 60)\n",
    "\n",
    "            train_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[:ss] and re.match(r'.*[23]ft.*', sample_key) is None} \n",
    "            test_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if audiodatasets.get_sentence_id(sample_key) in sample[ss:] and re.match(r'.*[23]ft.*', sample_key) is None } \n",
    "            eval_sample = { sample_key:evasive_todo[\"RECORDED\"][sample_key] for sample_key in evasive_todo[\"RECORDED\"] \\\n",
    "                                                             if not audiodatasets.get_sentence_id(sample_key) in sample and re.match(r'.*[23]ft.*', sample_key) is None } \n",
    "\n",
    "            pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(f\"{jar}/{samples_fn}\", 'wb'))\n",
    "\n",
    "            evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "            evaluation_dictionary[\"Evaluation Autoencoder Key\"] = ae_id\n",
    "            evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"RECORDED\"]\n",
    "            evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"RECORDED\"\n",
    "            evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"RECORDED\"]\n",
    "\n",
    "            populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "            pops = []\n",
    "            for x in populations:\n",
    "                pops.append([])\n",
    "                for y in x:\n",
    "                    pops[-1].append(list(y))\n",
    "\n",
    "            populations = pops\n",
    "            pickle.dump( populations, open(f\"{jar}/{pops_fn}\", 'wb'))\n",
    "\n",
    "        print(f\"Completed trial {trial_indx}\")\n",
    "        misc.elapsedTime()\n",
    "    \n",
    "# Part 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# 20 Sep 2022 - New setup for defense testing\n",
    "#######################################\n",
    "\n",
    "misc.resetTimer()\n",
    "\n",
    "# Part 1: Train on RAVDESS for 40 generations\n",
    "\n",
    "# Setup the evaluation environment\n",
    "evaluation_dictionary = {}\n",
    "evaluation_dictionary[\"Evaluation File List\"] = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                                                 if audiodatasets.get_sentence_id(sample_key) in ravdess_sentence_ids } \n",
    "evaluation_dictionary[\"Evaluation Sample Size\"] = 40\n",
    "\n",
    "# We are starting with a pretrained model, so we need to go w/o any info about the target environment E\n",
    "evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "evaluation_dictionary[\"Evaluation Autoencoder Key\"] = None\n",
    "evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "evaluation_dictionary[\"Target Class\"] = None\n",
    "evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "gp.initialize_gp_environment(fitness_function=evaluation)\n",
    "\n",
    "\n",
    "# Part 1: Initialize the population on RAVDESS data \n",
    "print(\"\\n=======================================================================================\")\n",
    "print(f\"RAVDESS/TESS: RAVDESS Digital run\")\n",
    "print(\"=======================================================================================\\n\")\n",
    "\n",
    "ravdess_pickle_fn = os.path.join(jar, 'populations_START_RAVDESS40_PLUS_TESS_10GEN_DEFENSE.pickle')\n",
    "if os.path.exists(ravdess_pickle_fn):\n",
    "    ravdess_populations = pickle.load(open(ravdess_pickle_fn, 'rb'))\n",
    "else:\n",
    "    ravdess_populations, _ = gp.run_gp(starting_population=None, number_of_generations=40)\n",
    "    pickle.dump(ravdess_populations, open(ravdess_pickle_fn, 'wb'))\n",
    "\n",
    "print(f\"Completed.\")\n",
    "misc.elapsedTime()\n",
    "\n",
    "# Part 2: Train on a subset of the TESS dataset\n",
    "# Build train/test/eval split on TESS data based upon sentence ID (want to ensure that each split has disjoint utterances) \n",
    "num_trials = 1\n",
    "\n",
    "# percentage of stuff in train and test; eval is everything else\n",
    "trn_tst_eval = [25,25]\n",
    "\n",
    "for trial_indx in range(num_trials):\n",
    "    trn_sz = trn_tst_eval[0]\n",
    "    tst_sz = trn_tst_eval[1]\n",
    "    eval_sz = 100 - trn_sz - tst_sz\n",
    "    \n",
    "    print(\"\\n=======================================================================================\")\n",
    "    print(f\"RAVDESS/TESS: Splits {trn_sz}%_{tst_sz}%_{eval_sz}%, Trial {trial_indx+1} of {num_trials}\")\n",
    "    print(\"=======================================================================================\\n\")\n",
    "\n",
    "    # Filenames for saving the details from this run\n",
    "    pops_fn = f\"populations_{trial_indx:02}_samples_{trn_sz}_{tst_sz}_{eval_sz}_RAVDESS40_PLUS_TESS_10GEN_DEFENSE.pickle\"\n",
    "    samples_fn = f\"samples_{trial_indx:02}_samples_{trn_sz}_{tst_sz}_{eval_sz}_RAVDESS40_PLUS_TESS_10GEN_DEFENSE.pickle\"\n",
    "\n",
    "    # Skip this run if we've already finished it\n",
    "    if not os.path.exists(os.path.join(jar, pops_fn)):\n",
    "        sentence_ids = list(tess_sentence_ids)\n",
    "        random.shuffle(sentence_ids)\n",
    "        \n",
    "        train_len = len(sentence_ids)*trn_sz//100\n",
    "        test_len = len(sentence_ids)*tst_sz//100\n",
    "        \n",
    "        train_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                            if audiodatasets.get_sentence_id(sample_key) in sentence_ids[:train_len] }\n",
    "        \n",
    "        test_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                            if audiodatasets.get_sentence_id(sample_key) in sentence_ids[train_len:train_len+test_len] }\n",
    "        \n",
    "        eval_sample = { sample_key:evasive_todo[\"PURE\"][sample_key] for sample_key in evasive_todo[\"PURE\"] \\\n",
    "                            if audiodatasets.get_sentence_id(sample_key) in sentence_ids[train_len+test_len:] }\n",
    "        \n",
    "\n",
    "        # Save these samples for later eval\n",
    "        pickle.dump( {\"TRAIN\": train_sample, \"TEST\":test_sample, \"EVAL\": eval_sample}, open(os.path.join(jar, samples_fn), 'wb'))\n",
    "\n",
    "        # Set the eval environment \n",
    "        evaluation_dictionary[\"Evaluation File List\"] = train_sample\n",
    "        evaluation_dictionary[\"Evaluation Autoencoder Key\"] = \"PURE\"\n",
    "        evaluation_dictionary[\"Original Transcription Confidences\"] = valid_confidences[\"PURE\"]\n",
    "        evaluation_dictionary[\"Evaluation Classifier Modality\"] = \"PURE\"\n",
    "        evaluation_dictionary[\"Original Softmax Values\"] = original_softmax_values[\"PURE\"]\n",
    "\n",
    "        # Iterate for 10 more generations using the TESS training data from above\n",
    "        populations,_ = gp.run_gp(starting_population=ravdess_populations[-1], number_of_generations=10)\n",
    "\n",
    "        # Dump the population info for later\n",
    "        pops = []\n",
    "        for x in populations:\n",
    "            pops.append([])\n",
    "            for y in x:\n",
    "                pops[-1].append(list(y))\n",
    "\n",
    "        populations = pops\n",
    "        pickle.dump( populations, open(os.path.join(jar, pops_fn), 'wb'))\n",
    "\n",
    "        print(f\"Completed trial {trial_indx}\")\n",
    "        misc.elapsedTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
